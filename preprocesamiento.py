# -*- coding: utf-8 -*-
"""Analitica en Recursos Humanos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NES0mYyId3aVCRg_2xIfWw1LlJ4uR0Ch
"""

# Commented out IPython magic to ensure Python compatibility.
# Importar librerias necesarias
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# %matplotlib inline

df_data= pd.read_csv("general_data.csv", sep= ';' ) #Se carga base 1
df_data.head(3)

df_retiros= pd.read_csv("retirement_info.csv", sep= ';' ) #Se carga base 2
df_retiros.head(3)

df_employee= pd.read_csv("employee_survey_data.csv", sep= ',' ) #Se carga base 3
df_employee.head(3)

df_manager= pd.read_csv("manager_survey_data.csv", sep= ',' ) #Se carga base 4
df_manager.head(3)

print(df_data.shape)  #Se muestra el tamaño de cada base cargada
print(df_retiros.shape)
print(df_employee.shape)
print(df_manager.shape)

df_data.info()

df_retiros.info()

df_employee.info()

df_manager.info()

df2=pd.merge(df_data, df_retiros, how = 'left', on = 'EmployeeID').merge(df_employee, how = 'left', on = 'EmployeeID').merge(df_manager, how = 'left', on = 'EmployeeID')
df2

df2.info()

##Gráficos variables categóricas
plt.figure(figsize=(20, 10))
plt.subplot(3,4,1)
df2['BusinessTravel'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,2)
df2['Department'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,3)
df2['EducationField'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,4)
df2['Gender'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,5)
df2['JobRole'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,6)
df2['MaritalStatus'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,7)
df2['Over18'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,8)
df2['Attrition'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,9)
df2['retirementDate'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,10)
df2['retirementType'].value_counts().plot(kind='pie',autopct='%.2f')
plt.subplot(3,4,11)
df2['resignationReason'].value_counts().plot(kind='pie',autopct='%.2f')

"""De la gráficas anteriores se puede concluir que las variables Over 18 y Attrition se pueden eliminar, ya que solo contienen una categoría y para todos los datos es la misma, entonces no tiene ninguna relevancia en el modelo."""

##Gráficos de las variables numéricas
df2.hist(bins=30, figsize=(20, 15))

"""#  LIMPIEZA Y TRANSFORMACION DE LOS DATOS"""

df2.info() #Visualizar tipos de datos de cada variable

df2.isnull().sum() #Mirar la cantidad de nulos de cada variable

"""Se procede a hacer el tratamiento de datos nulos:
Para las variables de EnvironmentSatisfaction, JobSatisfaction, WorkLifeBalance se procede a realizar una imputación de los datos por la moda, ya que aunque la base de datos muestre que es una variable numérica.
"""

#Definir imputer para variables numéricas
imp_num = SimpleImputer(strategy='most_frequent')
#Ajustar imputer y transformar las variables con valores null
imp_num.fit(df2['EnvironmentSatisfaction'].values.reshape(-1,1))
imp_num.fit(df2['JobSatisfaction'].values.reshape(-1,1))
imp_num.fit(df2['WorkLifeBalance'].values.reshape(-1,1))
df2['EnvironmentSatisfaction']= imp_num.transform(df2['EnvironmentSatisfaction'].values.reshape(-1,1))
df2['JobSatisfaction']= imp_num.transform(df2['JobSatisfaction'].values.reshape(-1,1))
df2['WorkLifeBalance']= imp_num.transform(df2['WorkLifeBalance'].values.reshape(-1,1))