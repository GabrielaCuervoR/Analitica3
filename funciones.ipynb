{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwaqBULK200E23ijRZ6HzI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielaCuervoR/Analitica3/blob/main/funciones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ofckZe46XA95"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer ### para imputación\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler ## escalar variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########Esta función permite ejecutar un archivo  con extensión .sql que contenga varias consultas\n",
        "def ejecutar_sql (nombre_archivo, cur):\n",
        "  sql_file=open(nombre_archivo)\n",
        "  sql_as_string=sql_file.read()\n",
        "  sql_file.close\n",
        "  cur.executescript(sql_as_string)"
      ],
      "metadata": {
        "id": "Rn-KA6hBXLEi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para imputar las variables categoricas\n",
        "def imputar_fc(df, list_cat):\n",
        "  df_c = df[list_cat]\n",
        "\n",
        "  imputer_c = SimpleImputer(strategy='most_frequent')\n",
        "  imputer_c.fit(df_c)\n",
        "  X_c = imputer_c.transform(df_c)\n",
        "  df_c = pd.DataFrame(X_c, columns=df_c.columns)\n",
        "\n",
        "  df[list_cat] = df_c  # Actualizar las columnas imputadas en el DataFrame original\n",
        "  return df"
      ],
      "metadata": {
        "id": "CN6w6sX_Xwlo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para imputar variables numericas:\n",
        "def imputar_fn(df, list_num):\n",
        "  df_n = df[list_num]\n",
        "\n",
        "  imputer_n = SimpleImputer(strategy='median')\n",
        "  imputer_n.fit(df_n)\n",
        "  X_n = imputer_n.transform(df_n)\n",
        "  df_n = pd.DataFrame(X_n, columns=df_n.columns)\n",
        "\n",
        "  df[list_num] = df_n  # Actualizar las columnas imputadas en el DataFrame original\n",
        "  return df"
      ],
      "metadata": {
        "id": "JOeKLyXTjcdY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Función para seleccionar variables\n",
        "def sel_variables(modelos,X,y,threshold):\n",
        "\n",
        "  var_names_ac=np.array([])\n",
        "  for modelo in modelos:\n",
        "      #modelo=modelos[i]\n",
        "      modelo.fit(X,y)\n",
        "      sel = SelectFromModel(modelo, prefit=True,threshold=threshold)\n",
        "      var_names= modelo.feature_names_in_[sel.get_support()]\n",
        "      var_names_ac=np.append(var_names_ac, var_names)\n",
        "      var_names_ac=np.unique(var_names_ac)\n",
        "\n",
        "  return var_names_ac"
      ],
      "metadata": {
        "id": "0NEJbdEnNx85"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Función para los modelos\n",
        "def medir_modelos(modelos,scoring,X,y,cv):\n",
        "\n",
        "  metric_modelos=pd.DataFrame()\n",
        "  for modelo in modelos:\n",
        "      scores=cross_val_score(modelo,X,y, scoring=scoring, cv=cv )\n",
        "      pdscores=pd.DataFrame(scores)\n",
        "      metric_modelos=pd.concat([metric_modelos,pdscores],axis=1)\n",
        "\n",
        "  metric_modelos.columns=[\"logistic_regresion\",\"random_forest\",\"decision_tree\",\"gradient_boosting\"]\n",
        "  return metric_modelos"
      ],
      "metadata": {
        "id": "uuEBS1T9N6MY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preparar_datos (df):\n",
        "\n",
        "  #### Cargar modelo y listas\n",
        "\n",
        "\n",
        "  list_cat=joblib.load(\"list_cat.pkl\")\n",
        "  list_num=joblib.load(\"list_num.pkl\")\n",
        "  list_dummies=joblib.load(\"list_dummies.pkl\")\n",
        "  var_names=joblib.load(\"var_names.pkl\")\n",
        "  scaler=joblib.load( \"scaler.pkl\")\n",
        "\n",
        "  ####Ejecutar funciones de transformaciones\n",
        "\n",
        "  df=funciones.imputar_fc(df,list_cat)\n",
        "  df=funciones.imputar_fn(df,list_num)\n",
        "  df_dummies=pd.get_dummies(df,columns=list_dummies)\n",
        "  df_dummies= df_dummies.loc[:,~df_dummies.columns.isin(['Attrition','EmployeeID'])]\n",
        "  X2=scaler.transform(df_dummies)\n",
        "  X=pd.DataFrame(X2,columns=df_dummies.columns)\n",
        "  X=X[var_names]\n",
        "\n",
        "\n",
        "  return X"
      ],
      "metadata": {
        "id": "z5Da6fPwOCsD"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}
